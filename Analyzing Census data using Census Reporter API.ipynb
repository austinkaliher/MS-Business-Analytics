{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Census data using Census Reporter API\n",
    "## By: Austin Kaliher\n",
    "### This piece of code was originally created for APRD 6342 (Digital Advertising) at the University of Colorado Boulder. This assignment involves analyzing census data to find optimal target markets for a local coffee roaster. To do this, we called the census reporter API to get the raw data to analyze. From prelimiary research, we found people age 18-34, households that earn 50k - 75k per year, and latino people were the optimal targeting characteristics for the client. Our assignment was to then identiy the metro areas in the United States that have the highest population of people in those groups. Data for this code is available in my repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'msas.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f1754597c998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import the CBSA data (geographical region identifiers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0malldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'msas.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# The age, income, and ethnicity data we are looking for are located in these tables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'msas.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Import the CBSA data (geographical region identifiers)\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "\n",
    "# The age, income, and ethnicity data we are looking for are located in these tables\n",
    "# I am constructing a string that can be placed into the URL for the API calls\n",
    "tableids = ['B01001', 'B03002', 'B19001']\n",
    "tableidstring = ','.join(tableids)\n",
    "geoid = alldata['CBSA']\n",
    "\n",
    "# Initialize the destination dictionary for the API calls\n",
    "recdata = {}\n",
    "\n",
    "# API calls to get data. time.sleep(1) is used to make the program pause one second in\n",
    "# between API calls. Without this, the API will usually fail due to too many requests.\n",
    "for row in range(len(geoid)):\n",
    "    requesturl = 'http://api.censusreporter.org/1.0/data/show/latest?table_ids=%s&geo_ids=31000US%s' % (tableidstring, geoid[row])\n",
    "    recdata[row] = requests.get(requesturl).json()\n",
    "    time.sleep(1)\n",
    "\n",
    "# Getting count of people aged between 18 - 34 by geoid. Age groups reported in the\n",
    "# census data only span a few years so all these cateogries must be called to get data\n",
    "# for people age 18-34\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "age1 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    age1[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B01001']['estimate']['B01001031']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "age2 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    age2[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B01001']['estimate']['B01001032']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "age3 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    age3[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B01001']['estimate']['B01001033']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "age4 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    age4[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B01001']['estimate']['B01001034']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "age5 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    age5[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B01001']['estimate']['B01001035']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "age6 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    age6[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B01001']['estimate']['B01001036']\n",
    "age = age1 + age2 + age3 + age4 + age5 + age6\n",
    "\n",
    "# Getting count of people with household income between $50k and $75k by geoid\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "income1 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    income1[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B19001']['estimate']['B19001011']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "income2 = geoid\n",
    "for row in range(len(recdata)):\n",
    "    income2[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B19001']['estimate']['B19001012']\n",
    "income = income1 + income2\n",
    "\n",
    "# Getting count of people that identify as hispanic by geoid\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "hisp = geoid\n",
    "for row in range(len(recdata)):\n",
    "    hisp[row] = recdata[row]['data']['31000US' + str(int(geoid[row]))]['B03002']['estimate']['B03002012']\n",
    "alldata = pd.read_csv('msas.csv')\n",
    "geoid = alldata['CBSA']\n",
    "\n",
    "# Questions 1 - 3\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Question 1. The city with the highest population of people with household')\n",
    "print('income of 50k to 75k')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('When we analyze the data, we see that the highest person count for a city is:')\n",
    "print(' ')\n",
    "print(max(income))\n",
    "print(' ')\n",
    "print('When we reference back to the tables, we see that the city with this population is:')\n",
    "print(' ')\n",
    "print('The New York area')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Question 2. The city with the highest population with people aged 18 to 34.')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('When we analyze the data, we see that the highest person count for a city is:')\n",
    "print(' ')\n",
    "print(max(age))\n",
    "print(' ')\n",
    "print('When we reference back to the tables, we see that the city with this population is:')\n",
    "print(' ')\n",
    "print('The New York area')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Question 3. The city with the largest latino population')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('When we analyze the data, we see that the highest person count for a city is:')\n",
    "print(' ')\n",
    "print(max(hisp))\n",
    "print(' ')\n",
    "print('When we reference back to the tables, we see that the city with this population is:')\n",
    "print(' ')\n",
    "print('Los Angeles/Long Beach')\n",
    "\n",
    "\n",
    "# Question 4\n",
    "\n",
    "perincome = income\n",
    "perage = age\n",
    "perhisp = hisp\n",
    "perincome = perincome / max(income)\n",
    "perage = perage / max(age)\n",
    "perhisp = perhisp / max(hisp)\n",
    "totalper = (perincome + perage + perhisp) / 3\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('Question 4. The city with the largest average percentage across categories')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('When we analyze the data, we see that the highest percentage is:')\n",
    "print(' ')\n",
    "print(max(totalper))\n",
    "print(' ')\n",
    "print('When we reference back to the tables, we see that the city with this population is:')\n",
    "print(' ')\n",
    "print('New York area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
